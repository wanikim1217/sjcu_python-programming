{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **NLP - 텍스트데이터 분석과 서비스 활용 (스팸메일분류)**\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "drIFNkR0Lstc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **품사 분류하기**"
      ],
      "metadata": {
        "id": "CmgwPc4zVCgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy\n",
        " \n",
        "from konlpy.tag import Okt\n",
        " \n",
        "text = '''4차 산업혁명 시대의 핵심 기술을 리드하는 글로벌 수준 융합형 컴퓨터·AI 전문가 양성\n",
        "인공지능 전문가과정, 컴퓨터 전문가과정, 클라우드전문가 과정, 드론/IoT(자율사물) 전문가 과정, 빅데이터/데이터과학\n",
        "전문가과정을 통해 사회가 요구하는 전문가 양성, 세종사이버대학교 컴퓨터·AI공학과에서 준비하세요.'''\n",
        " \n",
        "okt = Okt()\n",
        "result = okt.pos(text, norm=False, stem=False) \n",
        " \n",
        "print(result)"
      ],
      "metadata": {
        "id": "6lVH-zyjWEEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<출력결과>\n",
        "\n",
        "---\n",
        "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
        "Collecting konlpy\n",
        "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
        "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 19.4/19.4 MB 49.5 MB/s eta 0:00:00\n",
        "Collecting JPype1>=0.7.0\n",
        "  Downloading JPype1-1.4.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
        "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 465.3/465.3 kB 41.8 MB/s eta 0:00:00\n",
        "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.2)\n",
        "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.22.4)\n",
        "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.1)\n",
        "Installing collected packages: JPype1, konlpy\n",
        "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n",
        "\n",
        "[('4', 'Number'), ('차', 'Noun'), ('산업혁명', 'Noun'), ('시대', 'Noun'), ('의', 'Josa'), ('핵심', 'Noun'), ('기술', 'Noun'), ('을', 'Josa'), ('리드', 'Noun'), ('하는', 'Verb'), ('글로벌', 'Noun'), ('수준', 'Noun'), ('융합', 'Noun'), ('형', 'Suffix'), ('컴퓨터', 'Noun'), ('·', 'Punctuation'), ('AI', 'Alpha'), ('전문가', 'Noun'), ('양성', 'Noun'), ('\\n', 'Foreign'), ('인공', 'Noun'), ('지능', 'Noun'), ('전문가', 'Noun'), ('과정', 'Noun'), (',', 'Punctuation'), ('컴퓨터', 'Noun'), ('전문가', 'Noun'), ('과정', 'Noun'), (',', 'Punctuation'), ('클라우드', 'Noun'), ('전문가', 'Noun'), ('과정', 'Noun'), (',', 'Punctuation'), ('드론', 'Noun'), ('/', 'Punctuation'), ('IoT', 'Alpha'), ('(', 'Punctuation'), ('자율', 'Noun'), ('사물', 'Noun'), (')', 'Punctuation'), ('전문가', 'Noun'), ('과정', 'Noun'), (',', 'Punctuation'), ('빅데이터', 'Noun'), ('/', 'Punctuation'), ('데이터', 'Noun'), ('과학', 'Noun'), ('\\n', 'Foreign'), ('전문가', 'Noun'), ('과정', 'Noun'), ('을', 'Josa'), ('통해', 'Noun'), ('사회', 'Noun'), ('가', 'Josa'), ('요구', 'Noun'), ('하는', 'Verb'), ('전문가', 'Noun'), ('양성', 'Noun'), (',', 'Punctuation'), ('세종', 'Noun'), ('사이버', 'Noun'), ('대학교', 'Noun'), ('컴퓨터', 'Noun'), ('·', 'Punctuation'), ('AI', 'Alpha'), ('공', 'Modifier'), ('학과', 'Noun'), ('에서', 'Josa'), ('준비', 'Noun'), ('하세요', 'Verb'), ('.', 'Punctuation')]\n"
      ],
      "metadata": {
        "id": "OXN4sXidVojg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **워드 카운트**"
      ],
      "metadata": {
        "id": "Rk7QSUP_WVBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        " \n",
        "corpus = ['''반짝반짝 작은 별 \n",
        "아름답게 비치네 \n",
        "동쪽 하늘에서도 \n",
        "서쪽 하늘에서도 \n",
        "반짝반짝 작은 별 \n",
        "아름답게 비치네''']\n",
        "vector = CountVectorizer()\n",
        " \n",
        "print(vector.fit_transform(corpus).toarray()) # 코퍼스 분석\n",
        "print(vector.vocabulary_)   "
      ],
      "metadata": {
        "id": "aou7wl9xWZZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<출력결과>\n",
        "\n",
        "---\n",
        "\n",
        "[[1 2 2 1 2 2 2]]\n",
        "\n",
        "{'반짝반짝': 1, '작은': 5, '아름답게': 4, '비치네': 2, '동쪽': 0, '하늘에서도': 6, '서쪽': 3}\n"
      ],
      "metadata": {
        "id": "-PJKLKzfWpJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **워드 벡터**"
      ],
      "metadata": {
        "id": "FWRiStENW6Za"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        " \n",
        "import nltk\n",
        "from nltk.corpus import movie_reviews\n",
        "from gensim.models.word2vec import Word2Vec\n",
        " \n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('punkt')\n",
        " \n",
        "sentences = [list(s) for s in movie_reviews.sents()]\n",
        "model = Word2Vec(sentences)\n",
        " \n",
        "print(model.wv.similarity('actor', 'actress'))\n",
        "print(model.wv.similarity('he', 'she'))\n",
        "print(model.wv.most_similar(positive=['actress', 'he'], negative=['she'])[0])"
      ],
      "metadata": {
        "id": "JWdHGvM1XA3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<출력결과>\n",
        "\n",
        "\n",
        "---\n",
        "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
        "Requirement already satisfied: gensim in /usr/local/lib/python3.8/dist-packages (3.6.0)\n",
        "\n",
        "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.7.3)\n",
        "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (6.3.0)\n",
        "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.21.6)\n",
        "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.15.0)\n",
        "\n",
        "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
        "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
        "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
        "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
        "\n",
        "0.8691156\n",
        "\n",
        "0.85135794\n",
        "\n",
        "('actor', 0.8114767074584961)\n"
      ],
      "metadata": {
        "id": "aXd8EvmwXCLJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **나이브베이즈 분류 모델 - 스팸메일분류의 예**"
      ],
      "metadata": {
        "id": "jOLF46d2XWf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        " \n",
        "# 훈련 데이터 (텍스트)\n",
        "corpus = [\"광고 쇼핑몰 가격 선물 세일\",\n",
        "          \"투자 수익 소식 등급\",\n",
        "          \"쿠폰 선물 무료 익일 배송\",\n",
        "          \"백화점 상품 파격 세일\",\n",
        "          \"프로젝트 보고서 지급\",\n",
        "          \"회의 일정 변경\"]\n",
        " \n",
        "# 훈련라벨 ())0: 일반, 1: 스팸)\n",
        "label = [1,1,1,1,0,0]\n",
        " \n",
        "vector = CountVectorizer()\n",
        "train = vector.fit_transform(corpus).toarray()\n",
        " \n",
        "# 나이브 베이즈 분류 모델 생성\n",
        "model = BernoulliNB()\n",
        "model.fit(train, label) # 학습\n",
        " \n",
        "data = [\"백화점 세일 무료 배송 알찬\"]\n",
        "test = vector.transform(data).toarray()\n",
        " \n",
        "result = model.predict(test)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "ToGGl4nLXemg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<출력결과>\n",
        "\n",
        "\n",
        "---\n",
        "[1]\n"
      ],
      "metadata": {
        "id": "ErxsRZ6oXiAY"
      }
    }
  ]
}